version: '3.8'

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.6.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
    ports:
      - "2181:2181"
    networks:
      - pipeline-net
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    networks:
      - pipeline-net
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s

  nifi:
    image: apache/nifi:1.25.0
    container_name: nifi
    environment:
      - NIFI_WEB_HTTP_PORT=8080
      - NIFI_WEB_HTTPS_PORT=
      - NIFI_SECURITY_USER_LOGIN_IDENTITY_PROVIDER=single-user-provider
      - SINGLE_USER_CREDENTIALS_USERNAME=admin
      - SINGLE_USER_CREDENTIALS_PASSWORD=ctsBtRBKHRAx69EqUghvvgEvjnaLjFEB
      - NIFI_SENSITIVE_PROPS_KEY=12345678901234567890123456789012
      - NIFI_JVM_HEAP_INIT=1g
      - NIFI_JVM_HEAP_MAX=2g
      - NIFI_WEB_PROXY_HOST=localhost:8080
    ports:
      - "8080:8080"
    volumes:
      - nifi_data:/opt/nifi/nifi-current/conf
      - nifi_flowfile:/opt/nifi/nifi-current/flowfile_repository
      - nifi_content:/opt/nifi/nifi-current/content_repository
      - nifi_provenance:/opt/nifi/nifi-current/provenance_repository
      - nifi_state:/opt/nifi/nifi-current/state
      - nifi_logs:/opt/nifi/nifi-current/logs
    networks:
      - pipeline-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/nifi"]
      interval: 30s
      timeout: 10s
      retries: 10
      start_period: 300s

  minio:
    image: minio/minio:RELEASE.2024-10-13T13-34-11Z
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    networks:
      - pipeline-net
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 10s
      timeout: 5s
      retries: 5

  minio-init:
    image: minio/mc:RELEASE.2024-10-08T09-37-26Z
    container_name: minio-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set myminio http://minio:9000 minioadmin minioadmin;
      mc mb --ignore-existing myminio/datalake;
      mc mb --ignore-existing myminio/warehouse;
      mc mb --ignore-existing myminio/raw-data;
      mc mb --ignore-existing myminio/processed-data;
      mc anonymous set download myminio/datalake;
      echo 'MinIO buckets created successfully';
      exit 0;
      "
    networks:
      - pipeline-net

  flink-jobmanager:
    image: flink:1.18-scala_2.12-java11
    container_name: flink-jobmanager
    user: "flink:flink"
    command: >
      bash -c "
      mkdir -p /opt/flink/plugins/s3-fs-hadoop &&
      cp /opt/flink/opt/flink-s3-fs-hadoop-*.jar /opt/flink/plugins/s3-fs-hadoop/ &&
      mkdir -p /tmp/flink-checkpoints /tmp/flink-savepoints &&
      /docker-entrypoint.sh jobmanager
      "
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 4
        parallelism.default: 2
        state.backend: filesystem
        state.checkpoints.dir: s3a://datalake/flink-checkpoints
        state.savepoints.dir: s3a://datalake/flink-savepoints
        s3.endpoint: http://minio:9000
        s3.access-key: minioadmin
        s3.secret-key: minioadmin
        s3.path.style.access: true
    ports:
      - "8081:8081"
    volumes:
      - ./flink-jars:/opt/flink/usrlib
      - flink_checkpoints:/tmp/flink-checkpoints
      - flink_savepoints:/tmp/flink-savepoints
    networks:
      - pipeline-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8081"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  flink-taskmanager:
    image: flink:1.18-scala_2.12-java11
    container_name: flink-taskmanager
    user: "flink:flink"
    command: >
      bash -c "
      mkdir -p /opt/flink/plugins/s3-fs-hadoop &&
      cp /opt/flink/opt/flink-s3-fs-hadoop-*.jar /opt/flink/plugins/s3-fs-hadoop/ &&
      mkdir -p /tmp/flink-checkpoints &&
      /docker-entrypoint.sh taskmanager
      "
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 4
        taskmanager.memory.process.size: 1g
        s3.endpoint: http://minio:9000
        s3.access-key: minioadmin
        s3.secret-key: minioadmin
        s3.path.style.access: true
    depends_on:
      flink-jobmanager:
        condition: service_healthy
    volumes:
      - flink_checkpoints:/tmp/flink-checkpoints
    networks:
      - pipeline-net

  trino:
    image: trinodb/trino:435
    container_name: trino
    ports:
      - "8082:8082"
    volumes:
      - ./trino/catalog:/etc/trino/catalog
      - ./trino/config.properties:/etc/trino/config.properties
    networks:
      - pipeline-net
    depends_on:
      minio-init:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8082/v1/info"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

networks:
  pipeline-net:
    driver: bridge

volumes:
  zookeeper_data:
  zookeeper_logs:
  kafka_data:
  minio_data:
  nifi_data:
  nifi_flowfile:
  nifi_content:
  nifi_provenance:
  nifi_state:
  nifi_logs:
  flink_checkpoints:
  flink_savepoints: